{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# -- coding: utf-8 --\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #初始化权重W参数，给权重制造一些随机噪声打破完全对称\n",
    "    #此处生成的是包含噪声的正态分布，噪声标准差设置为0.1\n",
    "    initial = tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "    \n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W, strides = [1,1,1,1],padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],\n",
    "                          padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备输入数据\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y_ = tf.placeholder(tf.float32,[None,10])\n",
    "#卷积神经网络要用到空间结构信息，将1维输入向量转为2维的图片结构\n",
    "#  1x784 -> 28x28  \n",
    "#  [-1,28,28,1] 其中-1代表样本数量不固定，最后1代表颜色通道数量，若为彩色则为3\n",
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始定义第一个卷积层。\n",
    "#[5,5,1,32]卷积核尺寸5x5,1个颜色通道，32个不同的卷积核\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第二个卷积层，卷积核数量为64，即这一层的卷积会提取64种特征\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#经过前面2次步长2x2的最大池化，变长为原来的1/4，即7x7\n",
    "#第二个卷积层的卷积核数量为64，输出的tensor尺寸为7x7x64\n",
    "#因输出为1维向量，故将其reshape为1维向量\n",
    "W_fc1 = weight_variable([7*7*64,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1, 7*7*64])\n",
    "#连接一个全连接层，隐藏节点为1024，使用relu激活函数\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#减轻过拟合，使用一个dropout层\n",
    "#Dropout用法：通过一个placeholder传入keep_prob比率来控制\n",
    "#训练时随机丢弃一部分节点减轻过拟合\n",
    "#但预测时则保留全部数据来追求最好的预测性能\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最后将dropout层连接到softmax层得到最后概率并输出\n",
    "W_fc2 = weight_variable([1024,10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义LOSS FUNCTION为cross_entropy  优化器使用Adam,学习率 1e-4\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ *tf.log(y_conv),\n",
    "                                             reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义评测准确率的操作\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0,training accuracy is 0.14\n",
      "step 100,training accuracy is 0.82\n",
      "step 200,training accuracy is 0.92\n",
      "step 300,training accuracy is 0.9\n",
      "step 400,training accuracy is 0.96\n",
      "step 500,training accuracy is 0.96\n",
      "step 600,training accuracy is 0.92\n",
      "step 700,training accuracy is 0.98\n",
      "step 800,training accuracy is 0.96\n",
      "step 900,training accuracy is 1\n",
      "step 1000,training accuracy is 0.96\n",
      "step 1100,training accuracy is 0.98\n",
      "step 1200,training accuracy is 0.96\n",
      "step 1300,training accuracy is 1\n",
      "step 1400,training accuracy is 1\n",
      "step 1500,training accuracy is 0.98\n",
      "step 1600,training accuracy is 0.98\n",
      "step 1700,training accuracy is 1\n",
      "step 1800,training accuracy is 1\n",
      "step 1900,training accuracy is 0.98\n"
     ]
    }
   ],
   "source": [
    "#开始训练   依次初始化所有参数   keep_prob=0.5   \n",
    "# 使用大小50的mini-batch 进行共20000次训练迭代，参与训练样本数量共100W\n",
    "# 每100次训练 对准确率进行一次评测（评测时keep_prob设置为1）\n",
    "tf.global_variables_initializer().run()\n",
    "for i in range(2000):#20000\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict = {x:batch[0],y_:batch[1],\n",
    "                                                   keep_prob:1.0})\n",
    "        print(\"step %d,training accuracy is %g\"%(i,train_accuracy))\n",
    "    train_step.run(feed_dict = {x:batch[0],y_:batch[1],keep_prob:0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全部训练完成后，在最终的测试集上进行全面测试，得到整体的分类准确率\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x:mnist.test.images,\n",
    "                                                 y_:mnist.test.labels,\n",
    "                                                 keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
